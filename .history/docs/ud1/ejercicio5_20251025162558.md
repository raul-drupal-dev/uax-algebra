# Ejercicio 5 — Dependencia lineal

Considere $\mathbf{v}_1=(1,0,2),\;\mathbf{v}_2=(2,1,3),\;\mathbf{v}_3=(3,1,5).$

a) Determine si el conjunto $\{\mathbf{v}_1,\mathbf{v}_2,\mathbf{v}_3\}$ es linealmente dependiente o independiente.  
b) Justifique su respuesta usando determinantes o reducción por filas.

## a) ¿El conjunto es linealmente dependiente o independiente?

Un conjunto de vectores es linealmente independiente si la única combinación lineal que da el vector cero es la combinación trivial (todos los escalares cero). Si existe una combinación no trivial que dé cero, entonces son linealmente dependientes. Una forma práctica de comprobarlo en $\mathbb{R}^3$ es calcular el determinante de la matriz que tiene los vectores como columnas (o filas): si el determinante es distinto de cero, los vectores son independientes; si el determinante es cero, son dependientes.

Formemos la matriz con los vectores como columnas:

Partimos de la ecuación vectorial que planteamos para determinar si los vectores son linealmente dependientes:

$$
c_{1}\cdot \vec{v_{1}}+c_{2}\cdot \vec{v_{2}}+c_{3}\cdot \vec{v_{3}}=\vec{0}
$$

Con nuestros vectores, esto es:

$$
c_{1}\cdot \left|\begin{matrix}1\\\ 0\\\ 2\end{matrix}\right|+c_{2}\cdot \left|\begin{matrix}2\\\ 1\\\ 3\end{matrix}\right|+c_{3}\cdot \left|\begin{matrix}3\\\ 1\\\ 5\end{matrix}\right|=\left|\begin{matrix}0\\\ 0\\\ 0\end{matrix}\right|
$$

Recuerda que multiplicar un vector por un escalar significa multiplicar cada una de sus componentes por ese escalar. Así que expandimos la ecuación:

$$
\left|\begin{matrix}c_{1}\cdot 1\\\ c_{1}\cdot 0\\\ c_{1}\cdot 2\end{matrix}\right|+\left|\begin{matrix}c_{2}\cdot 2\\\ c_{2}\cdot 1\\\ c_{2}\cdot 3\end{matrix}\right|+\left|\begin{matrix}c_{3}\cdot 3\\\ c_{3}\cdot 1\\\ c_{3}\cdot 5\end{matrix}\right|=\left|\begin{matrix}0\\\ 0\\\ 0\end{matrix}\right|
$$

Esto se simplifica a:

$$
\left|\begin{matrix}c_{1}\\\ 0\\\ 2c_{1}\end{matrix}\right|+\left|\begin{matrix}2c_{2}\\\ c_{2}\\\ 3c_{2}\end{matrix}\right|+\left|\begin{matrix}3c_{3}\\\ c_{3}\\\ 5c_{3}\end{matrix}\right|=\left|\begin{matrix}0\\\ 0\\\ 0\end{matrix}\right|
$$

La suma de vectores se hace componente a componente. Sumamos todas las primeras componentes, luego todas las segundas, y así sucesivamente:

$$
\left|\begin{matrix}c_{1}+2c_{2}+3c_{3}\\\ 0+c_{2}+c_{3}\\\ 2c_{1}+3c_{2}+5c_{3}\end{matrix}\right|=\left|\begin{matrix}0\\\ 0\\\ 0\end{matrix}\right|
$$

Ahora, igualamos las componentes del vector de la izquierda con las del vector de la derecha (el vector nulo). Esto nos da un sistema de ecuaciones lineales: 

- Primera componente: $c_{1}+2c_{2}+3c_{3}=0$
- Segunda componente: $c_{2}+c_{3}=0$
- Tercera componente: $2c_{1}+3c_{2}+5c_{3}=0$


$$
M = \left|
\begin{matrix}
1 & 2 & 3 \\
0 & 1 & 1 \\
2 & 3 & 5
\end{matrix}
\right|
$$

Calculamos el determinante (o podemos usar reducción por filas). Cálculo directo:

$$
\det(M)= \begin{vmatrix}1 & 2 & 3\\ 0 & 1 & 1\\ 2 & 3 & 5\end{vmatrix}
= 1\cdot(1\cdot5 - 1\cdot3) - 2\cdot(0\cdot5 - 1\cdot2) + 3\cdot(0\cdot3 - 1\cdot2) =
$$

Evaluando:

$$
= 1(5-3) -2(0-2) +3(0-2) = 
$$

$$
= 2 -2(-2) +3(-2) =
$$
$= 2 +4 -6 = 0.

Como el determinante es 0, los vectores son linealmente dependientes.

---

## b) Justificación con reducción y relación explícita

Además de la comprobación por determinante, es instructivo encontrar la relación lineal explícita entre los vectores. Buscamos escalares $\alpha,\beta,\gamma$, no todos cero, tales que

$$
\alpha\mathbf{v}_1 + \beta\mathbf{v}_2 + \gamma\mathbf{v}_3 = \mathbf{0}.
$$

Planteando por componentes:

\begin{aligned}
\alpha + 2\beta + 3\gamma &= 0 \\ % componente x
0\alpha + 1\beta + 1\gamma &= 0 \\ % componente y
2\alpha + 3\beta + 5\gamma &= 0 % componente z
\end{aligned}

De la segunda ecuación obtenemos inmediatamente $\beta = -\gamma$. Sustituimos en la primera y despejamos $\alpha$:

$$\alpha + 2(-\gamma) + 3\gamma = \alpha + \gamma = 0 \Rightarrow \alpha = -\gamma.$$

Ahora conviene verificar explícitamente por qué la tercera ecuación no aporta nueva información. Sustituimos $\alpha=-\gamma$ y $\beta=-\gamma$ en la tercera ecuación:

\begin{aligned}
2\alpha + 3\beta + 5\gamma &= 2(-\gamma) + 3(-\gamma) + 5\gamma \\
&= (-2-3+5)\,\gamma = 0\cdot\gamma = 0.
\end{aligned}

Por tanto la tercera ecuación queda $0=0$, una identidad que se cumple para cualquier $\gamma$. Eso muestra que la tercera ecuación es redundante —no impone restricción adicional— y deja un grado de libertad (parámetro libre) en las soluciones.

Otra forma de verlo es mediante eliminación de Gauss en la matriz de coeficientes (añadimos la columna de ceros a la derecha):

$$
\left[\begin{array}{ccc|c}
1 & 2 & 3 & 0 \\
0 & 1 & 1 & 0 \\
2 & 3 & 5 & 0
\end{array}\right]
\xrightarrow{R_3-2R_1}
\left[\begin{array}{ccc|c}
1 & 2 & 3 & 0 \\
0 & 1 & 1 & 0 \\
0 & -1 & -1 & 0
\end{array}\right]
\xrightarrow{R_3+R_2}
\left[\begin{array}{ccc|c}
1 & 2 & 3 & 0 \\
0 & 1 & 1 & 0 \\
0 & 0 & 0 & 0
\end{array}\right]
$$

La fila nula final confirma que hay una ecuación redundante y, por tanto, soluciones infinitas parametrizadas por, por ejemplo, $\gamma=t$. Sustituyendo $\gamma=t$ se obtiene $\beta=-t$, $\alpha=-t$, es decir

$$
(\alpha,\beta,\gamma)=(-t,-t,t),\qquad t\in\mathbb{R}.
$$

Elegimos $t=1$ para dar una relación concreta y no trivial entre los vectores.

Eligiendo $t=1$ obtenemos la relación no trivial

$$
-1\cdot\mathbf{v}_1 -1\cdot\mathbf{v}_2 +1\cdot\mathbf{v}_3 = \mathbf{0},
$$

es decir,

$$
\mathbf{v}_3 = \mathbf{v}_1 + \mathbf{v}_2.
$$

???+ Nota
    Hemos visto que $\mathbf{v}_3$ es combinación lineal de $\mathbf{v}_1$ y $\mathbf{v}_2$, lo que explica la dependencia lineal. Esto significa que los tres vectores no añaden nueva dirección; el conjunto de direcciones lo generan solo dos vectores independientes.

